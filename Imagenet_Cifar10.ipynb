{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 13:22:17.466765: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Tokenization and Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "with open('/pixel_document_train_cifar10.txt', 'r') as file:\n",
    "    pixel_document = file.read()\n",
    "    print(type(pixel_document))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_set = []\n",
    "for i in range(0, len(pixel_document), 32):\n",
    "  chunk = pixel_document[i:i+32]\n",
    "  document_set.append(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FXXF2m333mmmmmmmmmm33m3mmIIIIINI',\n",
       " '1Ar22mm222K22333mmK2333333333KK2',\n",
       " '1r22KKK22mm222222222mmmm33222FXX',\n",
       " '22333mKK33K2FF11KZr112m2333222Kr',\n",
       " '3K33KK33K3m111rrNN32rrr123333K33',\n",
       " 'I33333mm3mrK2K333Kq3qMq223333333',\n",
       " 'q3333mF222KM44iM555MMMMqK3333333',\n",
       " '333331F22qMI35z6886iiz68iq333333',\n",
       " '33333r2KM89qMii6hzzG549h6433333K',\n",
       " '32K33KZb8h44zzUII3qI45i66Im222m3',\n",
       " '323mm3UGz94344333I333IUUUIKK33Kq',\n",
       " '3K33333344455M33333333mmm3333345',\n",
       " 'qK333333444UGU943K3332kKK3333qMI',\n",
       " 'M43KKm3333mK3I33333333333333M5IF',\n",
       " '5444qq333333333333333Km333mFI411',\n",
       " '4444MMMMqqqqqq3qq33333KKKKrLqMKK']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_set[:16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2222m'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('ImageNet_ListVocabs_.json', 'r') as file:\n",
    "    list_of_vocabs = json.load(file)\n",
    "list_of_vocabs[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20736376"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_of_vocabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800000/800000 [00:07<00:00, 106979.15it/s]\n"
     ]
    }
   ],
   "source": [
    "def build_trie(priority_lists):\n",
    "    trie = {}\n",
    "    for word in priority_lists:\n",
    "        node = trie\n",
    "        for char in word:\n",
    "            node = node.setdefault(char, {})\n",
    "        node['$'] = word\n",
    "    return trie\n",
    "\n",
    "def match_and_extract(text, trie):\n",
    "    result = []\n",
    "    i = 0\n",
    "    while i < len(text):\n",
    "        node = trie\n",
    "        end = i\n",
    "        last_match = None\n",
    "        for j in range(i, len(text)):\n",
    "            if text[j] not in node:\n",
    "                break\n",
    "            node = node[text[j]]\n",
    "            if '$' in node:\n",
    "                last_match = node['$']\n",
    "                end = j + 1\n",
    "        if last_match:\n",
    "            result.append(last_match)\n",
    "            i = end\n",
    "        else:\n",
    "            i += 1\n",
    "    return result\n",
    "\n",
    "def preprocess_vocabs(list_of_vocabs):\n",
    "    trie = build_trie(list_of_vocabs)\n",
    "    vocab_dict = defaultdict(list)\n",
    "    for word in list_of_vocabs:\n",
    "        if word:\n",
    "            vocab_dict[word[0]].append(word)\n",
    "    return trie, vocab_dict\n",
    "\n",
    "def tokenize_documents(document_set, list_of_vocabs):\n",
    "    trie, vocab_dict = preprocess_vocabs(list_of_vocabs)\n",
    "    tokenized_documents = []\n",
    "\n",
    "    for document in tqdm(document_set):\n",
    "        tokenized_documents.append(match_and_extract(document, trie))\n",
    "\n",
    "    return tokenized_documents\n",
    "\n",
    "# Usage\n",
    "tokenized_documents = tokenize_documents(document_set, list_of_vocabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = []\n",
    "for i in range(0, len(tokenized_documents), 16):\n",
    "  group = tokenized_documents[i:i+16]\n",
    "  tokens = ''\n",
    "  for j in group:\n",
    "    tokens = ' '.join(j)\n",
    "    document.append(tokens)\n",
    "\n",
    "training_document = []\n",
    "for i in range(0, len(document), 16):\n",
    "  group = document[i:i+16]\n",
    "  tokens = ' '.join(group)\n",
    "  training_document.append(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FXXF2 m333m mmmmm mmmm3 3m3mm IIIII NI',\n",
       " '1Ar22 mm222 K2233 3mmK2 3333K K2',\n",
       " '1r22K KK22m m2222 2222m mmm33 222FX',\n",
       " '22333 mKK33 K2FF1 1KZr1 12m23 33222 Kr',\n",
       " '3K33K K33K3 m111r rNN32 rrr12 3333K',\n",
       " 'I3333 3mm3m rK2K3 33Kq3 qMq22',\n",
       " 'q3333 mF222 KM44i M555M MMMqK',\n",
       " '33331 F22qM I35z6 886ii z68iq',\n",
       " '3333r 2KM89 qMii6 hzzG5 49h64 3333K',\n",
       " '32K33 KZb8h 44zzU II3qI 45i66 Im222 m3',\n",
       " '323mm 3UGz9 43443 33I33 3IUUU IKK33 Kq',\n",
       " '3K333 33344 455M3 3333m mm333 3345',\n",
       " 'qK333 33344 4UGU9 43K33 32kKK 3333q MI',\n",
       " 'M43KK m3333 mK3I3 3333M 5IF',\n",
       " '5444q q3333 3333K m333m FI411',\n",
       " '4444M MMMqq qqqq3 qq333 33KKK KrLqM KK']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document[:16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'FXXF2 m333m mmmmm mmmm3 3m3mm IIIII NI 1Ar22 mm222 K2233 3mmK2 3333K K2 1r22K KK22m m2222 2222m mmm33 222FX 22333 mKK33 K2FF1 1KZr1 12m23 33222 Kr 3K33K K33K3 m111r rNN32 rrr12 3333K I3333 3mm3m rK2K3 33Kq3 qMq22 q3333 mF222 KM44i M555M MMMqK 33331 F22qM I35z6 886ii z68iq 3333r 2KM89 qMii6 hzzG5 49h64 3333K 32K33 KZb8h 44zzU II3qI 45i66 Im222 m3 323mm 3UGz9 43443 33I33 3IUUU IKK33 Kq 3K333 33344 455M3 3333m mm333 3345 qK333 33344 4UGU9 43K33 32kKK 3333q MI M43KK m3333 mK3I3 3333M 5IF 5444q q3333 3333K m333m FI411 4444M MMMqq qqqq3 qq333 33KKK KrLqM KK'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_document[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_document)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Tokenization and Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "with open('/pixel_document_test_cifar10.txt', 'r') as file:\n",
    "    result_string_test = file.read()\n",
    "    print(type(result_string_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_document_set = []\n",
    "for i in range(0, len(result_string_test), 32):\n",
    "  chunk = result_string_test[i:i+32]\n",
    "  test_document_set.append(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['33333333333333333333333333333332',\n",
       " '3333333333qqq33333mmm222mmm33333',\n",
       " '3333333333IGI3mg22233333K222m333',\n",
       " '3312333333333qK2K22I43333221Fm33',\n",
       " 'MqKq4333Mblq44322222343K22221Fm3',\n",
       " '5345M3q3Uz545M33K21Ki44m23K221r2',\n",
       " '5345II43244q56Mq33r4543222mKK222',\n",
       " '5q55q234K3qif94II32494Im2m333mK3',\n",
       " '6M555K34qKIUII33m3qINIIm22m3K333',\n",
       " 'z555542II4q233qMKmI3qmFF12K3q333',\n",
       " 'I55554m4fuZZZl55MqK2F1rr22333mmm',\n",
       " 'm9955Ml87hGNNNNNm2222222222mm222',\n",
       " 'K2mI94i7YN22222222222222K3333KK3',\n",
       " '32222I6hIK222222222222mmm22233mm',\n",
       " '322222mUm222mmK22K2222222KK33212',\n",
       " '33222222222222FF2m333222334Im222']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_document_set[:16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_document_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 160000/160000 [00:01<00:00, 108237.07it/s]\n"
     ]
    }
   ],
   "source": [
    "test_tokenized_documents = tokenize_documents(test_document_set, list_of_vocabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = []\n",
    "for i in range(0, len(test_tokenized_documents), 16):\n",
    "  group = test_tokenized_documents[i:i+16]\n",
    "  tokens = ''\n",
    "  for j in group:\n",
    "    tokens = ' '.join(j)\n",
    "    document.append(tokens)\n",
    "\n",
    "testing_document = []\n",
    "for i in range(0, len(document), 16):\n",
    "  group = document[i:i+16]\n",
    "  tokens = ' '.join(group)\n",
    "  testing_document.append(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['33332',\n",
       " '3333q qq333 33mmm 222mm m3333',\n",
       " '3333I GI3mg 22233 333K2 22m33',\n",
       " '33123 3333q K2K22 I4333 3221F m33',\n",
       " 'MqKq4 333Mb lq443 22223 43K22 221Fm',\n",
       " '5345M 3q3Uz 545M3 3K21K i44m2 3K221 r2',\n",
       " '5345I I4324 4q56M q33r4 54322 2mKK2',\n",
       " '5q55q 234K3 qif94 II324 94Im2 m333m K3',\n",
       " '6M555 K34qK IUII3 3m3qI NIIm2 2m3K3',\n",
       " 'z5555 42II4 q233q MKmI3 qmFF1 2K3q3',\n",
       " 'I5555 4m4f uZZZl 55MqK 2F1rr 22333 mmm',\n",
       " 'm9955 Ml87h GNNNN Nm222 2222m m222',\n",
       " 'K2mI9 4i7YN 2222K 3333K K3',\n",
       " '32222 I6hI K2222 2222m mm222 33mm',\n",
       " '32222 2mUm2 22mmK 22K22 2222K K3321',\n",
       " '33222 2222F F2m33 32223 34Im2']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document[:16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'33332 3333q qq333 33mmm 222mm m3333 3333I GI3mg 22233 333K2 22m33 33123 3333q K2K22 I4333 3221F m33 MqKq4 333Mb lq443 22223 43K22 221Fm 5345M 3q3Uz 545M3 3K21K i44m2 3K221 r2 5345I I4324 4q56M q33r4 54322 2mKK2 5q55q 234K3 qif94 II324 94Im2 m333m K3 6M555 K34qK IUII3 3m3qI NIIm2 2m3K3 z5555 42II4 q233q MKmI3 qmFF1 2K3q3 I5555 4m4f uZZZl 55MqK 2F1rr 22333 mmm m9955 Ml87h GNNNN Nm222 2222m m222 K2mI9 4i7YN 2222K 3333K K3 32222 I6hI K2222 2222m mm222 33mm 32222 2mUm2 22mmK 22K22 2222K K3321 33222 2222F F2m33 32223 34Im2'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_document[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testing_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('training_document_cifar10_imagenet.json', 'w') as file:\n",
    "    json.dump(training_document, file)\n",
    "with open('testing_document_cifar10_imagenet.json', 'w') as file:\n",
    "    json.dump(testing_document, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.load('/Cifar 10/y_train_cifar10.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.load('/y_test_cifar10.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6,\n",
       " 9,\n",
       " 9,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 7,\n",
       " 8,\n",
       " 3,\n",
       " 4,\n",
       " 7,\n",
       " 7,\n",
       " 2,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 3,\n",
       " 2,\n",
       " 6,\n",
       " 4,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 2,\n",
       " 6,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 9,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 7,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 7,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 9,\n",
       " 5,\n",
       " 7,\n",
       " 9,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 8,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 9,\n",
       " 7,\n",
       " 8,\n",
       " 5,\n",
       " 9,\n",
       " 6,\n",
       " 7,\n",
       " 3,\n",
       " 1,\n",
       " 9,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 7,\n",
       " 7,\n",
       " 4,\n",
       " 7,\n",
       " 9,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 8,\n",
       " 0,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 8,\n",
       " 3,\n",
       " 9,\n",
       " 6,\n",
       " 6,\n",
       " 1,\n",
       " 8,\n",
       " 5,\n",
       " 2,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 1,\n",
       " 7,\n",
       " 7,\n",
       " 0,\n",
       " 0,\n",
       " 6,\n",
       " 9,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 9,\n",
       " 2,\n",
       " 6,\n",
       " 6,\n",
       " 1,\n",
       " 9,\n",
       " 5,\n",
       " 0,\n",
       " 4,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 1,\n",
       " 8,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 8,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 6,\n",
       " 2,\n",
       " 4,\n",
       " 9,\n",
       " 9,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 6,\n",
       " 7,\n",
       " 4,\n",
       " 6,\n",
       " 8,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 8,\n",
       " 4,\n",
       " 7,\n",
       " 6,\n",
       " 0,\n",
       " 9,\n",
       " 5,\n",
       " 1,\n",
       " 3,\n",
       " 8,\n",
       " 2,\n",
       " 7,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 7,\n",
       " 0,\n",
       " 4,\n",
       " 7,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 0,\n",
       " 9,\n",
       " 6,\n",
       " 9,\n",
       " 0,\n",
       " 8,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 0,\n",
       " 6,\n",
       " 1,\n",
       " 9,\n",
       " 3,\n",
       " 6,\n",
       " 9,\n",
       " 1,\n",
       " 3,\n",
       " 9,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 1,\n",
       " 0,\n",
       " 9,\n",
       " 5,\n",
       " 8,\n",
       " 5,\n",
       " 2,\n",
       " 9,\n",
       " 0,\n",
       " 8,\n",
       " 8,\n",
       " 0,\n",
       " 6,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 6,\n",
       " 3,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 0,\n",
       " 6,\n",
       " 6,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 5,\n",
       " 8,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 1,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 3,\n",
       " 8,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 0,\n",
       " 9,\n",
       " 3,\n",
       " 7,\n",
       " 4,\n",
       " 9,\n",
       " 9,\n",
       " 2,\n",
       " 4,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 0,\n",
       " 5,\n",
       " 9,\n",
       " 0,\n",
       " 8,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 5,\n",
       " 6,\n",
       " 3,\n",
       " 2,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 6,\n",
       " 0,\n",
       " 7,\n",
       " 9,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 5,\n",
       " 9,\n",
       " 9,\n",
       " 0,\n",
       " 8,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 6,\n",
       " 3,\n",
       " 3,\n",
       " 9,\n",
       " 0,\n",
       " 7,\n",
       " 9,\n",
       " 7,\n",
       " 7,\n",
       " 9,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 6,\n",
       " 6,\n",
       " 8,\n",
       " 7,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 7,\n",
       " 5,\n",
       " 9,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 6,\n",
       " 6,\n",
       " 0,\n",
       " 8,\n",
       " 1,\n",
       " 6,\n",
       " 2,\n",
       " 9,\n",
       " 2,\n",
       " 5,\n",
       " 9,\n",
       " 6,\n",
       " 7,\n",
       " 4,\n",
       " 1,\n",
       " 8,\n",
       " 7,\n",
       " 3,\n",
       " 6,\n",
       " 9,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 5,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 8,\n",
       " 5,\n",
       " 4,\n",
       " 7,\n",
       " 2,\n",
       " 3,\n",
       " 9,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 1,\n",
       " 4,\n",
       " 7,\n",
       " 0,\n",
       " 1,\n",
       " 7,\n",
       " 3,\n",
       " 1,\n",
       " 8,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 9,\n",
       " 0,\n",
       " 9,\n",
       " 6,\n",
       " 8,\n",
       " 2,\n",
       " 7,\n",
       " 7,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 8,\n",
       " 9,\n",
       " 4,\n",
       " 2,\n",
       " 7,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 9,\n",
       " 4,\n",
       " 8,\n",
       " 5,\n",
       " 1,\n",
       " 7,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 6,\n",
       " 9,\n",
       " 0,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 8,\n",
       " 0,\n",
       " 4,\n",
       " 8,\n",
       " 8,\n",
       " 1,\n",
       " 5,\n",
       " 2,\n",
       " 6,\n",
       " 8,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 7,\n",
       " 7,\n",
       " 5,\n",
       " 9,\n",
       " 6,\n",
       " 2,\n",
       " 8,\n",
       " 3,\n",
       " 4,\n",
       " 7,\n",
       " 3,\n",
       " 9,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 8,\n",
       " 1,\n",
       " 8,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 7,\n",
       " 1,\n",
       " 3,\n",
       " 9,\n",
       " 8,\n",
       " 0,\n",
       " 1,\n",
       " 7,\n",
       " 5,\n",
       " 8,\n",
       " 2,\n",
       " 8,\n",
       " 0,\n",
       " 4,\n",
       " 1,\n",
       " 8,\n",
       " 9,\n",
       " 8,\n",
       " 2,\n",
       " 9,\n",
       " 9,\n",
       " 2,\n",
       " 7,\n",
       " 5,\n",
       " 7,\n",
       " 3,\n",
       " 8,\n",
       " 8,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 7,\n",
       " 1,\n",
       " 6,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 6,\n",
       " 9,\n",
       " 7,\n",
       " 6,\n",
       " 2,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 7,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 9,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 7,\n",
       " 8,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 7,\n",
       " 6,\n",
       " 9,\n",
       " 8,\n",
       " 0,\n",
       " 6,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 8,\n",
       " 4,\n",
       " 0,\n",
       " 1,\n",
       " 8,\n",
       " 8,\n",
       " 1,\n",
       " 5,\n",
       " 7,\n",
       " 6,\n",
       " 4,\n",
       " 5,\n",
       " 8,\n",
       " 7,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 8,\n",
       " 4,\n",
       " 7,\n",
       " 3,\n",
       " 8,\n",
       " 8,\n",
       " 2,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 1,\n",
       " 6,\n",
       " 8,\n",
       " 1,\n",
       " 9,\n",
       " 7,\n",
       " 8,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 8,\n",
       " 8,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 5,\n",
       " 0,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 9,\n",
       " 9,\n",
       " 0,\n",
       " 9,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 7,\n",
       " 5,\n",
       " 6,\n",
       " 0,\n",
       " 8,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 8,\n",
       " 4,\n",
       " 6,\n",
       " 9,\n",
       " 9,\n",
       " 7,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 6,\n",
       " 7,\n",
       " 4,\n",
       " 9,\n",
       " 1,\n",
       " 6,\n",
       " 2,\n",
       " 7,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 6,\n",
       " 7,\n",
       " 5,\n",
       " 7,\n",
       " 6,\n",
       " 8,\n",
       " 9,\n",
       " 0,\n",
       " 9,\n",
       " 4,\n",
       " 4,\n",
       " 7,\n",
       " 0,\n",
       " 9,\n",
       " 4,\n",
       " 9,\n",
       " 6,\n",
       " 9,\n",
       " 4,\n",
       " 5,\n",
       " 7,\n",
       " 9,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 9,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 9,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 0,\n",
       " 7,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 6,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 5,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 9,\n",
       " 8,\n",
       " 4,\n",
       " 9,\n",
       " 8,\n",
       " 0,\n",
       " 2,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 1,\n",
       " 8,\n",
       " 8,\n",
       " 3,\n",
       " 6,\n",
       " 9,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 7,\n",
       " 6,\n",
       " 5,\n",
       " 3,\n",
       " 0,\n",
       " 5,\n",
       " 0,\n",
       " 5,\n",
       " 0,\n",
       " 8,\n",
       " 2,\n",
       " 6,\n",
       " 7,\n",
       " 3,\n",
       " 8,\n",
       " 2,\n",
       " 1,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 1,\n",
       " 0,\n",
       " 9,\n",
       " 5,\n",
       " 5,\n",
       " 0,\n",
       " 1,\n",
       " 7,\n",
       " 6,\n",
       " 9,\n",
       " 0,\n",
       " 4,\n",
       " 7,\n",
       " 7,\n",
       " 1,\n",
       " 5,\n",
       " 9,\n",
       " 4,\n",
       " 0,\n",
       " 8,\n",
       " 5,\n",
       " 9,\n",
       " 9,\n",
       " 6,\n",
       " 7,\n",
       " 1,\n",
       " 8,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 8,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 5,\n",
       " 3,\n",
       " 8,\n",
       " 2,\n",
       " 3,\n",
       " 7,\n",
       " 2,\n",
       " 9,\n",
       " 3,\n",
       " 8,\n",
       " 7,\n",
       " 8,\n",
       " 2,\n",
       " 7,\n",
       " 9,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 6,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 8,\n",
       " 0,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 2,\n",
       " 7,\n",
       " 0,\n",
       " 1,\n",
       " 7,\n",
       " 7,\n",
       " 8,\n",
       " 2,\n",
       " 9,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 7,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 7,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 6,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 9,\n",
       " 4,\n",
       " 3,\n",
       " 8,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 9,\n",
       " 3,\n",
       " 1,\n",
       " 8,\n",
       " 9,\n",
       " 3,\n",
       " 9,\n",
       " 9,\n",
       " 2,\n",
       " 9,\n",
       " 4,\n",
       " 8,\n",
       " 2,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 1,\n",
       " 5,\n",
       " 3,\n",
       " 6,\n",
       " 8,\n",
       " 7,\n",
       " 6,\n",
       " 9,\n",
       " 8,\n",
       " 0,\n",
       " 6,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 5,\n",
       " 8,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 7,\n",
       " 6,\n",
       " 9,\n",
       " 7,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 2,\n",
       " 4,\n",
       " 7,\n",
       " 0,\n",
       " 5,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 6,\n",
       " 1,\n",
       " 6,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 8,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 7,\n",
       " 3,\n",
       " 9,\n",
       " 4,\n",
       " 7,\n",
       " 9,\n",
       " 7,\n",
       " 3,\n",
       " 7,\n",
       " 2,\n",
       " 8,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 1,\n",
       " 2,\n",
       " 9,\n",
       " 0,\n",
       " 4,\n",
       " 8,\n",
       " 7,\n",
       " 3,\n",
       " 9,\n",
       " 8,\n",
       " 7,\n",
       " 7,\n",
       " 0,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 0,\n",
       " 5,\n",
       " 6,\n",
       " 2,\n",
       " 8,\n",
       " 5,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 5,\n",
       " 7,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 3,\n",
       " 5,\n",
       " ...]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = y_train.tolist()\n",
    "y_train = [item for sublist in y_train for item in sublist]\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3,\n",
       " 8,\n",
       " 8,\n",
       " 0,\n",
       " 6,\n",
       " 6,\n",
       " 1,\n",
       " 6,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 9,\n",
       " 5,\n",
       " 7,\n",
       " 9,\n",
       " 8,\n",
       " 5,\n",
       " 7,\n",
       " 8,\n",
       " 6,\n",
       " 7,\n",
       " 0,\n",
       " 4,\n",
       " 9,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 0,\n",
       " 9,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 9,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 9,\n",
       " 5,\n",
       " 4,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 0,\n",
       " 9,\n",
       " 3,\n",
       " 9,\n",
       " 7,\n",
       " 6,\n",
       " 9,\n",
       " 8,\n",
       " 0,\n",
       " 3,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 7,\n",
       " 4,\n",
       " 6,\n",
       " 7,\n",
       " 3,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 7,\n",
       " 2,\n",
       " 6,\n",
       " 8,\n",
       " 8,\n",
       " 0,\n",
       " 2,\n",
       " 9,\n",
       " 3,\n",
       " 3,\n",
       " 8,\n",
       " 8,\n",
       " 1,\n",
       " 1,\n",
       " 7,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 0,\n",
       " 3,\n",
       " 8,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 7,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 6,\n",
       " 8,\n",
       " 7,\n",
       " 4,\n",
       " 0,\n",
       " 6,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 2,\n",
       " 7,\n",
       " 8,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 8,\n",
       " 0,\n",
       " 8,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 8,\n",
       " 9,\n",
       " 1,\n",
       " 2,\n",
       " 9,\n",
       " 7,\n",
       " 2,\n",
       " 9,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 3,\n",
       " 8,\n",
       " 7,\n",
       " 6,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 8,\n",
       " 9,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 5,\n",
       " 2,\n",
       " 9,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 6,\n",
       " 6,\n",
       " 8,\n",
       " 4,\n",
       " 8,\n",
       " 4,\n",
       " 5,\n",
       " 0,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 3,\n",
       " 7,\n",
       " 5,\n",
       " 0,\n",
       " 0,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 8,\n",
       " 6,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 5,\n",
       " 8,\n",
       " 0,\n",
       " 1,\n",
       " 7,\n",
       " 2,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 8,\n",
       " 5,\n",
       " 1,\n",
       " 8,\n",
       " 7,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 5,\n",
       " 7,\n",
       " 9,\n",
       " 7,\n",
       " 4,\n",
       " 5,\n",
       " 9,\n",
       " 8,\n",
       " 0,\n",
       " 7,\n",
       " 9,\n",
       " 8,\n",
       " 2,\n",
       " 7,\n",
       " 6,\n",
       " 9,\n",
       " 4,\n",
       " 3,\n",
       " 9,\n",
       " 6,\n",
       " 4,\n",
       " 7,\n",
       " 6,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 8,\n",
       " 8,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 8,\n",
       " 9,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 9,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 3,\n",
       " 9,\n",
       " 9,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 9,\n",
       " 8,\n",
       " 1,\n",
       " 5,\n",
       " 7,\n",
       " 0,\n",
       " 8,\n",
       " 2,\n",
       " 4,\n",
       " 7,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 6,\n",
       " 3,\n",
       " 8,\n",
       " 5,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 9,\n",
       " 0,\n",
       " 6,\n",
       " 1,\n",
       " 0,\n",
       " 9,\n",
       " 1,\n",
       " 0,\n",
       " 7,\n",
       " 9,\n",
       " 1,\n",
       " 2,\n",
       " 6,\n",
       " 9,\n",
       " 3,\n",
       " 4,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 2,\n",
       " 6,\n",
       " 1,\n",
       " 8,\n",
       " 2,\n",
       " 1,\n",
       " 6,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 7,\n",
       " 7,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 7,\n",
       " 5,\n",
       " 4,\n",
       " 6,\n",
       " 1,\n",
       " 9,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 9,\n",
       " 3,\n",
       " 8,\n",
       " 0,\n",
       " 7,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 5,\n",
       " 8,\n",
       " 5,\n",
       " 4,\n",
       " 6,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 7,\n",
       " 3,\n",
       " 2,\n",
       " 8,\n",
       " 0,\n",
       " 9,\n",
       " 5,\n",
       " 8,\n",
       " 1,\n",
       " 9,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 8,\n",
       " 1,\n",
       " 4,\n",
       " 7,\n",
       " 9,\n",
       " 4,\n",
       " 2,\n",
       " 7,\n",
       " 0,\n",
       " 7,\n",
       " 0,\n",
       " 6,\n",
       " 6,\n",
       " 9,\n",
       " 0,\n",
       " 9,\n",
       " 2,\n",
       " 8,\n",
       " 7,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 9,\n",
       " 6,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 9,\n",
       " 8,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 4,\n",
       " 0,\n",
       " 1,\n",
       " 8,\n",
       " 2,\n",
       " 7,\n",
       " 9,\n",
       " 3,\n",
       " 6,\n",
       " 1,\n",
       " 9,\n",
       " 0,\n",
       " 7,\n",
       " 3,\n",
       " 7,\n",
       " 4,\n",
       " 5,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 9,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 6,\n",
       " 2,\n",
       " 5,\n",
       " 3,\n",
       " 7,\n",
       " 3,\n",
       " 7,\n",
       " 2,\n",
       " 5,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 9,\n",
       " 9,\n",
       " 5,\n",
       " 7,\n",
       " 5,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 9,\n",
       " 7,\n",
       " 3,\n",
       " 9,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 7,\n",
       " 8,\n",
       " 3,\n",
       " 7,\n",
       " 8,\n",
       " 0,\n",
       " 5,\n",
       " 7,\n",
       " 6,\n",
       " 0,\n",
       " 5,\n",
       " 4,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 5,\n",
       " 5,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 5,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 8,\n",
       " 1,\n",
       " 1,\n",
       " 8,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 4,\n",
       " 6,\n",
       " 5,\n",
       " 4,\n",
       " 9,\n",
       " 4,\n",
       " 7,\n",
       " 9,\n",
       " 9,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 1,\n",
       " 5,\n",
       " 3,\n",
       " 8,\n",
       " 9,\n",
       " 5,\n",
       " 8,\n",
       " 5,\n",
       " 7,\n",
       " 0,\n",
       " 7,\n",
       " 0,\n",
       " 5,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 6,\n",
       " 9,\n",
       " 0,\n",
       " 9,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 2,\n",
       " 9,\n",
       " 0,\n",
       " 1,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 5,\n",
       " 9,\n",
       " 1,\n",
       " 6,\n",
       " 2,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 8,\n",
       " 5,\n",
       " 9,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 7,\n",
       " 6,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 9,\n",
       " 7,\n",
       " 9,\n",
       " 2,\n",
       " 6,\n",
       " 7,\n",
       " 1,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 8,\n",
       " 9,\n",
       " 7,\n",
       " 5,\n",
       " 4,\n",
       " 0,\n",
       " 8,\n",
       " 4,\n",
       " 0,\n",
       " 9,\n",
       " 3,\n",
       " 4,\n",
       " 8,\n",
       " 9,\n",
       " 6,\n",
       " 9,\n",
       " 2,\n",
       " 6,\n",
       " 1,\n",
       " 4,\n",
       " 7,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 8,\n",
       " 5,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 6,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 9,\n",
       " 6,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 5,\n",
       " 8,\n",
       " 6,\n",
       " 6,\n",
       " 2,\n",
       " 1,\n",
       " 7,\n",
       " 7,\n",
       " 1,\n",
       " 2,\n",
       " 7,\n",
       " 9,\n",
       " 9,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 5,\n",
       " 6,\n",
       " 8,\n",
       " 7,\n",
       " 6,\n",
       " 8,\n",
       " 3,\n",
       " 0,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 0,\n",
       " 7,\n",
       " 9,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 3,\n",
       " 9,\n",
       " 5,\n",
       " 6,\n",
       " 9,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 9,\n",
       " 4,\n",
       " 7,\n",
       " 6,\n",
       " 3,\n",
       " 8,\n",
       " 9,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 5,\n",
       " 9,\n",
       " 6,\n",
       " 4,\n",
       " 8,\n",
       " 9,\n",
       " 6,\n",
       " 9,\n",
       " 6,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 7,\n",
       " 8,\n",
       " 3,\n",
       " 8,\n",
       " 2,\n",
       " 7,\n",
       " 5,\n",
       " 7,\n",
       " 2,\n",
       " 4,\n",
       " 8,\n",
       " 7,\n",
       " 4,\n",
       " 2,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 8,\n",
       " 4,\n",
       " 9,\n",
       " 4,\n",
       " 8,\n",
       " 8,\n",
       " 1,\n",
       " 8,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 6,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 7,\n",
       " 9,\n",
       " 9,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 7,\n",
       " 0,\n",
       " 7,\n",
       " 9,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 2,\n",
       " 5,\n",
       " 9,\n",
       " 2,\n",
       " 9,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 6,\n",
       " 8,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 7,\n",
       " 0,\n",
       " 5,\n",
       " 4,\n",
       " 6,\n",
       " 1,\n",
       " 6,\n",
       " 4,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 6,\n",
       " 0,\n",
       " 5,\n",
       " 9,\n",
       " 1,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 0,\n",
       " 3,\n",
       " 9,\n",
       " 6,\n",
       " 8,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 7,\n",
       " 7,\n",
       " 1,\n",
       " 4,\n",
       " 7,\n",
       " 2,\n",
       " 7,\n",
       " 1,\n",
       " 4,\n",
       " 7,\n",
       " 4,\n",
       " 4,\n",
       " 8,\n",
       " 4,\n",
       " 7,\n",
       " 7,\n",
       " 5,\n",
       " 3,\n",
       " 7,\n",
       " 2,\n",
       " 0,\n",
       " 8,\n",
       " 9,\n",
       " 5,\n",
       " 8,\n",
       " 3,\n",
       " 6,\n",
       " 2,\n",
       " 0,\n",
       " 8,\n",
       " 7,\n",
       " 3,\n",
       " 7,\n",
       " 6,\n",
       " 5,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 9,\n",
       " 2,\n",
       " 7,\n",
       " 0,\n",
       " 7,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 4,\n",
       " 7,\n",
       " 9,\n",
       " 8,\n",
       " 9,\n",
       " 0,\n",
       " 7,\n",
       " 7,\n",
       " 0,\n",
       " 7,\n",
       " 8,\n",
       " 4,\n",
       " 6,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 7,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 8,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 7,\n",
       " 8,\n",
       " 4,\n",
       " 3,\n",
       " 0,\n",
       " 9,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 7,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 8,\n",
       " 7,\n",
       " 1,\n",
       " 6,\n",
       " 8,\n",
       " 8,\n",
       " 5,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 8,\n",
       " 8,\n",
       " 0,\n",
       " 6,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 5,\n",
       " 5,\n",
       " 8,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 7,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 9,\n",
       " 8,\n",
       " 9,\n",
       " 1,\n",
       " 7,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 9,\n",
       " 6,\n",
       " 1,\n",
       " 4,\n",
       " 7,\n",
       " 0,\n",
       " 3,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 7,\n",
       " 0,\n",
       " 6,\n",
       " 8,\n",
       " 1,\n",
       " 9,\n",
       " 2,\n",
       " 9,\n",
       " 0,\n",
       " 4,\n",
       " 7,\n",
       " 8,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 5,\n",
       " 8,\n",
       " 4,\n",
       " 6,\n",
       " 3,\n",
       " 8,\n",
       " 1,\n",
       " 3,\n",
       " 8,\n",
       " ...]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = y_test.tolist()\n",
    "y_test = [item for sublist in y_test for item in sublist]\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_elements = set(y_train)\n",
    "unique_elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature-Based Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results:\n",
      "Accuracy: 0.30\n",
      "\n",
      "Class-wise Metrics:\n",
      "  0:\n",
      "    Precision: 0.38\n",
      "    Recall: 0.23\n",
      "    F1-score: 0.28\n",
      "  1:\n",
      "    Precision: 0.41\n",
      "    Recall: 0.35\n",
      "    F1-score: 0.38\n",
      "  2:\n",
      "    Precision: 0.26\n",
      "    Recall: 0.10\n",
      "    F1-score: 0.14\n",
      "  3:\n",
      "    Precision: 0.22\n",
      "    Recall: 0.23\n",
      "    F1-score: 0.22\n",
      "  4:\n",
      "    Precision: 0.20\n",
      "    Recall: 0.56\n",
      "    F1-score: 0.30\n",
      "  5:\n",
      "    Precision: 0.34\n",
      "    Recall: 0.27\n",
      "    F1-score: 0.30\n",
      "  6:\n",
      "    Precision: 0.34\n",
      "    Recall: 0.42\n",
      "    F1-score: 0.37\n",
      "  7:\n",
      "    Precision: 0.43\n",
      "    Recall: 0.18\n",
      "    F1-score: 0.25\n",
      "  8:\n",
      "    Precision: 0.39\n",
      "    Recall: 0.26\n",
      "    F1-score: 0.31\n",
      "  9:\n",
      "    Precision: 0.35\n",
      "    Recall: 0.40\n",
      "    F1-score: 0.37\n",
      "\n",
      "Macro-averaged Metrics:\n",
      "Precision: 0.33\n",
      "Recall: 0.30\n",
      "F1-score: 0.29\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import math\n",
    "\n",
    "class NaiveBayes:\n",
    "    def __init__(self):\n",
    "        self.class_counts = defaultdict(int)\n",
    "        self.feature_counts = defaultdict(lambda: defaultdict(int))\n",
    "        self.vocab = set()\n",
    "\n",
    "    def train(self, documents, labels):\n",
    "        for doc, label in zip(documents, labels):\n",
    "            self.class_counts[label] += 1\n",
    "            features = self.extract_features(doc)\n",
    "            for feature in features:\n",
    "                self.feature_counts[label][feature] += 1\n",
    "                self.vocab.add(feature)\n",
    "\n",
    "    def extract_features(self, document):\n",
    "        return document.split()\n",
    "\n",
    "    def predict(self, document):\n",
    "        features = self.extract_features(document)\n",
    "        best_label = None\n",
    "        best_score = float('-inf')\n",
    "\n",
    "        for label in self.class_counts:\n",
    "            score = math.log(self.class_counts[label])\n",
    "            for feature in features:\n",
    "                if feature in self.vocab:\n",
    "                    score += math.log((self.feature_counts[label][feature] + 1) /\n",
    "                                      (self.class_counts[label] + len(self.vocab)))\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_label = label\n",
    "\n",
    "        return best_label\n",
    "\n",
    "    def evaluate(self, test_documents, test_labels):\n",
    "        predictions = [self.predict(doc) for doc in test_documents]\n",
    "\n",
    "        # Calculate confusion matrix\n",
    "        confusion_matrix = defaultdict(lambda: defaultdict(int))\n",
    "        for true_label, pred_label in zip(test_labels, predictions):\n",
    "            confusion_matrix[true_label][pred_label] += 1\n",
    "\n",
    "        # Calculate metrics\n",
    "        accuracy = sum(1 for true, pred in zip(test_labels, predictions) if true == pred) / len(test_labels)\n",
    "\n",
    "        metrics = {}\n",
    "        for label in set(test_labels):\n",
    "            tp = confusion_matrix[label][label]\n",
    "            fp = sum(confusion_matrix[other][label] for other in confusion_matrix if other != label)\n",
    "            fn = sum(confusion_matrix[label][other] for other in confusion_matrix[label] if other != label)\n",
    "\n",
    "            precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "            recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "            f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "            metrics[label] = {\n",
    "                'precision': precision,\n",
    "                'recall': recall,\n",
    "                'f1': f1\n",
    "            }\n",
    "\n",
    "        # Calculate macro-averaged metrics\n",
    "        macro_precision = sum(m['precision'] for m in metrics.values()) / len(metrics)\n",
    "        macro_recall = sum(m['recall'] for m in metrics.values()) / len(metrics)\n",
    "        macro_f1 = sum(m['f1'] for m in metrics.values()) / len(metrics)\n",
    "\n",
    "        return {\n",
    "            'accuracy': accuracy,\n",
    "            'class_metrics': metrics,\n",
    "            'macro_precision': macro_precision,\n",
    "            'macro_recall': macro_recall,\n",
    "            'macro_f1': macro_f1\n",
    "        }\n",
    "\n",
    "\n",
    "classifier = NaiveBayes()\n",
    "classifier.train(training_document, y_train)\n",
    "\n",
    "evaluation_results = classifier.evaluate(testing_document, y_test)\n",
    "\n",
    "print(\"Evaluation Results:\")\n",
    "print(f\"Accuracy: {evaluation_results['accuracy']:.2f}\")\n",
    "print(\"\\nClass-wise Metrics:\")\n",
    "for label, metrics in evaluation_results['class_metrics'].items():\n",
    "    print(f\"  {label}:\")\n",
    "    print(f\"    Precision: {metrics['precision']:.2f}\")\n",
    "    print(f\"    Recall: {metrics['recall']:.2f}\")\n",
    "    print(f\"    F1-score: {metrics['f1']:.2f}\")\n",
    "print(\"\\nMacro-averaged Metrics:\")\n",
    "print(f\"Precision: {evaluation_results['macro_precision']:.2f}\")\n",
    "print(f\"Recall: {evaluation_results['macro_recall']:.2f}\")\n",
    "print(f\"F1-score: {evaluation_results['macro_f1']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "\n",
    "# Step 3: Create TF-IDF Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Step 4: Fit and transform the training data\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(training_document)\n",
    "\n",
    "# Step 5: Transform the test data\n",
    "X_test_tfidf = tfidf_vectorizer.transform(testing_document)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.27\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.15      0.23      1000\n",
      "           1       0.48      0.20      0.28      1000\n",
      "           2       0.22      0.12      0.16      1000\n",
      "           3       0.23      0.23      0.23      1000\n",
      "           4       0.17      0.72      0.28      1000\n",
      "           5       0.37      0.23      0.28      1000\n",
      "           6       0.49      0.22      0.30      1000\n",
      "           7       0.56      0.07      0.12      1000\n",
      "           8       0.29      0.46      0.35      1000\n",
      "           9       0.34      0.28      0.31      1000\n",
      "\n",
      "    accuracy                           0.27     10000\n",
      "   macro avg       0.36      0.27      0.25     10000\n",
      "weighted avg       0.36      0.27      0.25     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Create and train the Naive Bayes classifier\n",
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Step 7: Make predictions on the test set\n",
    "y_pred = nb_classifier.predict(X_test_tfidf)\n",
    "\n",
    "# Step 8: Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM-linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.36\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.47      0.41      1000\n",
      "           1       0.41      0.42      0.42      1000\n",
      "           2       0.22      0.22      0.22      1000\n",
      "           3       0.23      0.22      0.22      1000\n",
      "           4       0.35      0.35      0.35      1000\n",
      "           5       0.33      0.31      0.32      1000\n",
      "           6       0.43      0.48      0.45      1000\n",
      "           7       0.45      0.32      0.37      1000\n",
      "           8       0.40      0.40      0.40      1000\n",
      "           9       0.43      0.40      0.41      1000\n",
      "\n",
      "    accuracy                           0.36     10000\n",
      "   macro avg       0.36      0.36      0.36     10000\n",
      "weighted avg       0.36      0.36      0.36     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Step 6: Create and train the SVM classifier\n",
    "svm_classifier = SVC(kernel='linear', random_state=42)\n",
    "svm_classifier.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Step 7: Make predictions on the test set\n",
    "y_pred = svm_classifier.predict(X_test_tfidf)\n",
    "\n",
    "# Step 8: Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM-rbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.36\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.44      0.41      1000\n",
      "           1       0.39      0.40      0.40      1000\n",
      "           2       0.27      0.23      0.25      1000\n",
      "           3       0.26      0.19      0.22      1000\n",
      "           4       0.34      0.34      0.34      1000\n",
      "           5       0.34      0.34      0.34      1000\n",
      "           6       0.37      0.52      0.44      1000\n",
      "           7       0.39      0.32      0.35      1000\n",
      "           8       0.44      0.41      0.42      1000\n",
      "           9       0.40      0.42      0.41      1000\n",
      "\n",
      "    accuracy                           0.36     10000\n",
      "   macro avg       0.36      0.36      0.36     10000\n",
      "weighted avg       0.36      0.36      0.36     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Step 6: Create and train the SVM classifier\n",
    "svm_classifier = SVC(kernel='rbf', random_state=42)\n",
    "svm_classifier.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Step 7: Make predictions on the test set\n",
    "y_pred = svm_classifier.predict(X_test_tfidf)\n",
    "\n",
    "# Step 8: Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.36\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.44      0.41      1000\n",
      "           1       0.42      0.41      0.42      1000\n",
      "           2       0.24      0.20      0.21      1000\n",
      "           3       0.23      0.18      0.20      1000\n",
      "           4       0.34      0.36      0.35      1000\n",
      "           5       0.34      0.34      0.34      1000\n",
      "           6       0.39      0.52      0.45      1000\n",
      "           7       0.41      0.33      0.37      1000\n",
      "           8       0.40      0.43      0.42      1000\n",
      "           9       0.40      0.40      0.40      1000\n",
      "\n",
      "    accuracy                           0.36     10000\n",
      "   macro avg       0.36      0.36      0.36     10000\n",
      "weighted avg       0.36      0.36      0.36     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "lr_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Step 7: Make predictions on the test set\n",
    "y_pred = lr_model.predict(X_test_tfidf)\n",
    "\n",
    "# Step 8: Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.23\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.16      0.20      1000\n",
      "           1       0.29      0.18      0.22      1000\n",
      "           2       0.16      0.12      0.14      1000\n",
      "           3       0.19      0.22      0.21      1000\n",
      "           4       0.22      0.45      0.29      1000\n",
      "           5       0.23      0.26      0.25      1000\n",
      "           6       0.31      0.23      0.27      1000\n",
      "           7       0.20      0.18      0.19      1000\n",
      "           8       0.31      0.25      0.27      1000\n",
      "           9       0.23      0.28      0.25      1000\n",
      "\n",
      "    accuracy                           0.23     10000\n",
      "   macro avg       0.24      0.23      0.23     10000\n",
      "weighted avg       0.24      0.23      0.23     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# Step 6: Scale the features\n",
    "scaler = StandardScaler(with_mean=False)\n",
    "X_train_scaled = scaler.fit_transform(X_train_tfidf)\n",
    "X_test_scaled = scaler.transform(X_test_tfidf)\n",
    "\n",
    "# Step 7: Create and train the MLP classifier\n",
    "mlp_classifier = MLPClassifier(hidden_layer_sizes=(100, 50),\n",
    "                               max_iter=500,\n",
    "                               activation='relu',\n",
    "                               solver='adam',\n",
    "                               random_state=42)\n",
    "mlp_classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Step 8: Make predictions on the test set\n",
    "y_pred = mlp_classifier.predict(X_test_scaled)\n",
    "\n",
    "# Step 9: Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.28\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.60      0.35      1000\n",
      "           1       0.33      0.32      0.32      1000\n",
      "           2       0.22      0.26      0.24      1000\n",
      "           3       0.23      0.14      0.17      1000\n",
      "           4       0.29      0.26      0.27      1000\n",
      "           5       0.28      0.12      0.17      1000\n",
      "           6       0.37      0.36      0.36      1000\n",
      "           7       0.29      0.11      0.16      1000\n",
      "           8       0.29      0.36      0.32      1000\n",
      "           9       0.32      0.29      0.31      1000\n",
      "\n",
      "    accuracy                           0.28     10000\n",
      "   macro avg       0.29      0.28      0.27     10000\n",
      "weighted avg       0.29      0.28      0.27     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_classifier = RandomForestClassifier()\n",
    "rf_classifier.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Step 7: Make predictions on the test set\n",
    "y_pred = rf_classifier.predict(X_test_tfidf)\n",
    "\n",
    "# Step 8: Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.32\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.48      0.40      1000\n",
      "           1       0.38      0.33      0.35      1000\n",
      "           2       0.24      0.23      0.24      1000\n",
      "           3       0.22      0.17      0.19      1000\n",
      "           4       0.27      0.29      0.28      1000\n",
      "           5       0.30      0.28      0.29      1000\n",
      "           6       0.36      0.43      0.39      1000\n",
      "           7       0.34      0.23      0.27      1000\n",
      "           8       0.35      0.42      0.38      1000\n",
      "           9       0.36      0.33      0.34      1000\n",
      "\n",
      "    accuracy                           0.32     10000\n",
      "   macro avg       0.32      0.32      0.31     10000\n",
      "weighted avg       0.32      0.32      0.31     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "xgb_classifier = xgb.XGBClassifier()\n",
    "xgb_classifier.fit(X_train_tfidf, y_train)\n",
    "\n",
    "y_pred = xgb_classifier.predict(X_test_tfidf)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
